
# ğŸ§  Document de RÃ©flexion â€“ Projet Suivi de RÃ©seau

## ğŸ§­ Introduction

### ğŸ“Œ PrÃ©sentation du sujet choisi

Dans le cadre du projet final de gestion de code source, jâ€™ai choisi lâ€™**option B** : le dÃ©veloppement dâ€™un outil de **suivi rÃ©seau** capable de scanner une plage dâ€™adresses IP. Ce choix sâ€™est imposÃ© naturellement, car il correspond Ã  des problÃ©matiques courantes dans le domaine de l'administration systÃ¨me et rÃ©seau, notamment la surveillance de la connectivitÃ© des Ã©quipements, lâ€™identification des machines actives sur un rÃ©seau local, et la dÃ©tection de services exposÃ©s via des ports ouverts.

Le projet consiste Ã  concevoir un utilitaire en ligne de commande capable de :
- **scanner une plage dâ€™IP** ou un fichier de configuration personnalisÃ© ;
- **afficher les IP actives ou inactives**, ainsi que leur **latence moyenne** ;
- **sauvegarder les rÃ©sultats** dans un fichier CSV ;
- **effectuer un scan asynchrone** pour amÃ©liorer la vitesse ;
- **dÃ©tecter les ports ouverts** (TCP) avec `nmap` sur les machines actives.

### ğŸ¯ Objectifs et organisation du projet

Lâ€™objectif principal Ã©tait de transformer un script basique en une application Python **structurÃ©e, modulaire, testÃ©e et documentÃ©e**, respectant les standards professionnels de dÃ©veloppement logiciel. Le projet devait aussi mettre en Å“uvre une **intÃ©gration continue**, une **documentation automatisÃ©e** et une **couverture de tests rigoureuse**.

Lâ€™organisation du projet a suivi une architecture claire :

- **`src/`** : contient le cÅ“ur de l'application, dÃ©coupÃ© en modules `core/` et `utils/`.
- **`tests/`** : inclut les tests unitaires couvrant les diffÃ©rents modules.
- **`docs/`** : contient la documentation Sphinx, structurÃ©e avec des fichiers `.rst`.
- **`data/`** : pour stocker les fichiers CSV d'entrÃ©e et de rÃ©sultats.
- **GitHub Actions** : gÃ¨re les workflows de test, linting et dÃ©ploiement de la documentation.

Chaque fonctionnalitÃ© a Ã©tÃ© conÃ§ue de maniÃ¨re modulaire, testÃ©e indÃ©pendamment, puis intÃ©grÃ©e dans une logique mÃ©tier unifiÃ©e accessible via un unique point dâ€™entrÃ©e : `main.py`. Lâ€™interface en ligne de commande repose sur `argparse`, permettant une utilisation souple et explicite pour lâ€™utilisateur final.


Voici une vue plus dÃ©taillÃ©e de lâ€™organisation technique du dÃ©pÃ´t :

- **.github/workflows/** : contient les fichiers YAML des workflows GitHub Actions :
  - `tests.yml` : exÃ©cute les tests unitaires, la couverture de code, `flake8` et `pylint`.
  - `deploy-doc.yml` : construit et dÃ©ploie la documentation Sphinx sur GitHub Pages.

- **data/** : contient les fichiers de configuration (`machines.csv`) et les rÃ©sultats de scan gÃ©nÃ©rÃ©s automatiquement en fonction du mode choisi (fichier ou plage IP).

- **docs/** : documentation Sphinx complÃ¨te avec fichiers `.rst`, configuration `conf.py`, et scripts de build (`Makefile`, `make.bat`).

- **src/** : cÅ“ur de lâ€™application Python, divisÃ© en deux sous-modules :
  - `core/` : logique rÃ©seau (ping, scan de ports, coordination, async/thread).
  - `utils/` : gestion CSV, parsing de latence, logger.

- **tests/** : tests unitaires couvrant tous les modules fonctionnels du projet, avec une trÃ¨s bonne couverture (y compris les cas asynchrones).

- **README.md** et **.gitignore** : fichiers classiques dâ€™accueil de projet et dâ€™exclusion Git.

## ğŸ› ï¸ DÃ©veloppement

### ğŸ”§ Ã‰tapes principales rÃ©alisÃ©es

1. CrÃ©ation de la structure initiale avec `src/`, `tests/`, `docs/` et `data/`.
2. DÃ©veloppement des modules principaux : `ping`, `runner`, `scanner_threaded`, `scanner_async`, `port_scanner`.
3. IntÃ©gration dâ€™un systÃ¨me de log (`logger.py`) et de parsing de la latence rÃ©seau (`parsing.py`).
4. Mise en place de la gestion des fichiers CSV en lecture/Ã©criture.
5. Ajout du support `argparse` pour gÃ©rer les entrÃ©es utilisateur.
6. ImplÃ©mentation des tests unitaires avec `unittest`, `patch`, `mock`, `AsyncMock`.
7. Configuration de lâ€™intÃ©gration continue avec GitHub Actions.
8. GÃ©nÃ©ration de la documentation avec Sphinx.

### ğŸ§± ProblÃ¨mes rencontrÃ©s et solutions apportÃ©es

Globalement, le dÃ©veloppement du projet sâ€™est bien dÃ©roulÃ© grÃ¢ce Ã  une architecture claire et Ã  une organisation en modules indÃ©pendants. Cependant, quelques dÃ©fis techniques ont nÃ©cessitÃ© des ajustements spÃ©cifiques :

- **CompatibilitÃ© multi-plateforme pour la rÃ©cupÃ©ration de la latence rÃ©seau**  
  Lors de lâ€™analyse des rÃ©sultats de commande `ping`, les formats de sortie variaient fortement selon lâ€™OS (Linux, Windows en franÃ§ais, Windows en anglais). Cela entraÃ®nait des Ã©checs dâ€™extraction de la latence.  
  â¤ Jâ€™ai corrigÃ© cela en Ã©largissant les expressions rÃ©guliÃ¨res dans `extract_latency()` pour prendre en charge tous les formats connus, avec un **fallback gÃ©nÃ©rique** qui capte des chaÃ®nes de type `time=XX ms` au cas oÃ¹ les formats standards Ã©choueraient.

- **DÃ©codage des sorties `ping` en asynchrone**  
  En mode asynchrone (`asyncio.create_subprocess_exec`), jâ€™ai rencontrÃ© des problÃ¨mes de dÃ©codage lorsque la sortie contenait des caractÃ¨res non UTF-8. Cela gÃ©nÃ©rait une `UnicodeDecodeError`.  
  â¤ Jâ€™ai mis en place un **systÃ¨me de dÃ©codage adaptatif** : tentative initiale en UTF-8, puis fallback en `latin1`, ce qui assure la compatibilitÃ© avec les encodages les plus courants.

- **Ã‰chec de rÃ©solution DNS avec certaines IP**  
  Pour les IP non associÃ©es Ã  un nom dâ€™hÃ´te, la fonction `socket.gethostbyaddr` levait une `socket.herror`, ce qui pouvait interrompre l'exÃ©cution.  
  â¤ Jâ€™ai encapsulÃ© cet appel dans un bloc `try/except` dans `resolve_hostname_if_needed()`, avec **retour de lâ€™IP brute comme fallback** si la rÃ©solution Ã©choue.

- **Tests unitaires pour fonctions asynchrones**  
  Tester les fonctions async (notamment `async_ping_ip`) demandait une structure diffÃ©rente du testing classique.  
  â¤ Jâ€™ai utilisÃ© `IsolatedAsyncioTestCase` ainsi que `AsyncMock` pour simuler les comportements asynchrones, ce qui a permis de couvrir correctement tous les cas, y compris les erreurs rÃ©seau simulÃ©es.

- **DisponibilitÃ© de Nmap en environnement GitHub Actions**  
  Le scan de ports nÃ©cessite `nmap`, qui nâ€™est pas prÃ©sent par dÃ©faut dans les runners GitHub.  
  â¤ Jâ€™ai ajoutÃ© son installation dans le workflow CI (`sudo apt-get install -y nmap`) pour garantir le bon dÃ©roulement des tests en mode `--ports`.


## ğŸ” Pipeline CI/CD

Le pipeline CI/CD a Ã©tÃ© mis en place avec **GitHub Actions** afin de garantir automatiquement la qualitÃ©, la stabilitÃ© et la maintenabilitÃ© du projet Ã  chaque modification du code source. Deux workflows distincts ont Ã©tÃ© crÃ©Ã©s et sont situÃ©s dans le dossier `.github/workflows/`.

---

### ğŸ§ª `tests.yml` â€“ Tests, couverture et qualitÃ© de code

Ce workflow est exÃ©cutÃ© Ã  chaque `push` ou `pull request` sur nâ€™importe quelle branche. Il a pour rÃ´le de :

- ğŸ” **Tester sur plusieurs versions de Python** : le projet est vÃ©rifiÃ© sous Python `3.8`, `3.10`, `3.11` et `3.12` pour sâ€™assurer de sa portabilitÃ©.
- ğŸ“¦ **Installer les dÃ©pendances** : `nmap`, `pip`, `flake8`, `pylint`, `coverage`, etc.
- âœ… **Analyser le code avec `flake8`** : dÃ©tecte les violations de la PEP8.
- ğŸ“Š **Ã‰valuer la qualitÃ© du code avec `pylint`** : avec un score minimum exigÃ© de **9.0/10**. Si ce score nâ€™est pas atteint, le workflow Ã©choue.
- ğŸ§ª **ExÃ©cuter les tests unitaires** : via `coverage run`, couvrant tous les modules du rÃ©pertoire `src/`.
- ğŸ“ˆ **GÃ©nÃ©rer un rapport de couverture HTML** et un rapport console dÃ©taillÃ©.
- â˜ï¸ **Uploader les rapports** (`flake8`, `pylint`, `htmlcov/`) comme artefacts tÃ©lÃ©chargeables dans lâ€™interface GitHub.

Ce pipeline permet de dÃ©tecter immÃ©diatement les rÃ©gressions, erreurs de style ou pertes de couverture dÃ¨s quâ€™une modification est introduite.

---

### ğŸ“˜ `deploy-doc.yml` â€“ Documentation automatique

Ce deuxiÃ¨me workflow est exÃ©cutÃ© Ã  chaque `push` ou `pull request`. Il sâ€™active plus prÃ©cisÃ©ment lorsque la branche `main` reÃ§oit un commit, et il :

- âœ… **Installe les dÃ©pendances Sphinx** (`sphinx`, `sphinx_rtd_theme`, `myst_parser`).
- ğŸ§± **Construit la documentation HTML** Ã  partir des fichiers `.rst` du dossier `docs/source/`.
- ğŸš€ **DÃ©ploie automatiquement la documentation** sur GitHub Pages (branche `gh-pages`) grÃ¢ce Ã  lâ€™action `peaceiris/actions-gh-pages@v3`.

Cela garantit que la documentation en ligne reste toujours **synchronisÃ©e avec le code source**, sans intervention manuelle.

---

### ğŸ§  Objectif du pipeline

Le pipeline CI/CD mis en place rÃ©pond aux objectifs suivants :
- **Assurer un niveau de qualitÃ© constant** Ã  chaque modification du projet.
- **Automatiser les tÃ¢ches rÃ©pÃ©titives** (tests, analyse statique, documentation).
- **Renforcer la confiance** dans les modifications via des validations automatiques.
- **Simplifier le travail de maintenance** et de revue de code, notamment en contexte collaboratif.

---

## âœ… Conclusion et auto-Ã©valuation

### ğŸ” Bilan personnel

ğŸŸ© Dans lâ€™ensemble, je suis satisfait du travail accompli. Le projet est bien structurÃ©, clair et respecte les conventions attendues dans un dÃ©veloppement Python professionnel. Toutes les fonctionnalitÃ©s obligatoires et avancÃ©es ont Ã©tÃ© correctement mises en Å“uvre, notamment le scan rÃ©seau asynchrone et la dÃ©tection de ports ouverts. Les tests unitaires sont nombreux, bien organisÃ©s et couvrent aussi bien les fonctions synchrones que les cas asynchrones, avec une bonne utilisation de `unittest`, `mock` et `AsyncMock`.

ğŸŸ© Le pipeline CI/CD rÃ©pond parfaitement aux attentes : il exÃ©cute les tests sur plusieurs versions de Python, vÃ©rifie la qualitÃ© du code avec `flake8` et `pylint`, mesure la couverture de code avec `coverage`, et gÃ©nÃ¨re automatiquement la documentation Sphinx. Cette documentation est structurÃ©e et accessible depuis GitHub Pages.

ğŸŸ¦ Cependant, certains points peuvent encore Ãªtre amÃ©liorÃ©s. Le fichier `README.md` pourrait Ãªtre enrichi avec des badges dâ€™intÃ©gration continue, une illustration du rendu de la documentation, et quelques exemples dâ€™utilisation visuelle.  
Par ailleurs, bien que le scan des ports soit fonctionnel avec `nmap`, lâ€™intÃ©gration dâ€™une solution en pur Python aurait rendu le projet plus portable.  
Enfin, il pourrait Ãªtre intÃ©ressant dâ€™ajouter un systÃ¨me dâ€™installation (comme un `setup.py` ou un `pyproject.toml`), ainsi que des tests dâ€™intÃ©gration simulant des scÃ©narios plus proches dâ€™un environnement rÃ©el.

ğŸŸ© Ce projet mâ€™a permis de renforcer mes compÃ©tences sur la structuration propre dâ€™un projet Python, et plus globalement sur lâ€™organisation dâ€™un dÃ©pÃ´t Git. Jâ€™ai Ã©galement consolidÃ© mes connaissances en intÃ©gration continue avec GitHub Actions, en documentation technique avec Sphinx, en Ã©criture de tests unitaires avancÃ©s (y compris pour des fonctions asynchrones), et en conception dâ€™outils rÃ©seau fiables, maintenables et bien documentÃ©s.


### ğŸ’ª Ce que jâ€™ai appris

- Lâ€™usage avancÃ© de `unittest`, notamment pour les cas asynchrones.
- La structuration propre dâ€™un projet Python et plus globalement sur git avec sÃ©paration claire des responsabilitÃ©s.
- La configuration de CI/CD avec GitHub Actions, et lâ€™importance de lâ€™automatisation.
- Lâ€™utilisation de `sphinx` pour documenter proprement un code Python complexe.
- Lâ€™Ã©criture de code rÃ©utilisable, testable et lisible.
